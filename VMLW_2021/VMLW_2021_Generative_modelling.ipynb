{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VMLW_2021_Generative_modelling",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDgl3ee8sVEt"
      },
      "source": [
        "## About Me & Us\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1BdlCq0QbQy_VKSSn1FTK7toAv6-pDyAE\" width=\"250\" />\n",
        "\n",
        "The author of this notebook is Donatas Repeƒçka, CTO and co-founder of the protein design company Biomatter Designs.\n",
        "\n",
        "[Biomatter Designs](https://www.biomatterdesigns.com/) is pioneering the technology for generative Protein Design for the next-generation manufacturing and therapeutic applications. The AI-based generative approach allows to effectively construct new enzymes and therapeutic proteins with the desired functions right from the first atom.\n",
        "\n",
        "\n",
        "Biomatter Designs strives to transform the protein engineering industry, which is currently dominated by slow and expensive experimental work into an industry that is driven by precise digital design of proteins for the development of novel biotherapeutics and sustainable manufacturing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWXWtIFPETJj"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this workshop I would like to demonstrate how GANs could be customized for data that is not images. In this specific case, we will use GANs to generate functional proteins. \n",
        "\n",
        "Prerequisites:\n",
        "* Understanding of Tensorflow library\n",
        "* Basic knowledge neural networks and their components\n",
        "* A general understanding about how GANs work\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SpqNBWGyTSJ"
      },
      "source": [
        "## Generative Adversarial Networks\n",
        " \n",
        "**Generative Adversarial Networks (GANs)** are powerful machine learning models capable of generating realistic examples.\n",
        " \n",
        "For example, an image below is generated by implementation of GAN called [StyleGAN 2](https://arxiv.org/abs/1912.04958)\n",
        " \n",
        "<img src=\"https://drive.google.com/uc?export=view&id=183HL6EPVXOzN1ukwKzudqdOYVsQktNlx\" width=400/>\n",
        " \n",
        "This is achieved by training two neural networks: discriminator and generator with opposite goals. Eventually, the generator becomes good at producing examples that are indistinguishable from true data distribution.\n",
        " \n",
        " \n",
        "Naturally, this ability to generate artificial examples with high quality from random numbers is something that could be successfully employed in other fields such as protein engineering.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q04P9icA8xIK"
      },
      "source": [
        "## Protein Engineering: Background\n",
        "\n",
        "Proteins are large, complex molecules that play many critical roles in living organisms, including humans. You can think of them as very tiny, programmable robots used by nature to perform various functions, e.g. building, modifying or breaking down other molecules, aiding in cell replication and division, and transporting other proteins inside of cells. Apart from the crucial cellular functions, proteins are used virtually everywhere in our daily life, starting from animal nutrition and washing powders down to costly drugs and therapeutic antibodies. Using synthetic biology, protein engineering, adaptive evolutions experimental techniques, researchers enhance proteins' properties, making them more active or \"sticky\" towards a particular drug target or resistant to harsh environemental conditions. However, it is challenging to randomly modify proteins in a \"biochemically meaningful\" way such that protein would remain functional leading in a very costly time-consuming experiments. Thus generating natural-like diverse proteins that remain functional is of outstanding importance for biotechnology and biomedical applications. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "6BRDjqgjZgkg",
        "outputId": "9a3888d1-4f23-41a8-85c0-f012cb96d080"
      },
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('wJyUtbn0O5Y', start=75, end=80, autoplay=1, controls=0, loop=1, width=800, height=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"600\"\n",
              "            src=\"https://www.youtube.com/embed/wJyUtbn0O5Y?start=75&end=80&autoplay=1&controls=0&loop=1\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f3e418773d0>"
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLPKgWGCZdL7"
      },
      "source": [
        "*Above, animation of motor protein responsible for transporting objects in cells*\n",
        "\n",
        "Source: https://www.youtube.com/watch?v=wJyUtbn0O5Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2PDRSD4kDTR"
      },
      "source": [
        "## Generative Adversarial Network in Synthetic Biology\n",
        "\n",
        "\n",
        "Proteins, like images, can be represented in various ways on the computer. Images are tensors of pixel intensities of red, green, and blue (RGB) colors which can be represented as integers from 0 to 255. Proteins, similarly, use letters to represent 20 unique amino acids, like the one below: \n",
        "\n",
        "> MKYATLLEYAFQALKNSYAPYSRFRVGAALLSDDGEVVTGCNVENASYGLSMCAERTAVFRAVAQGVKKFDAIAVVSGKVNPVYPCGACRQVLREFNPRLTVVVAGPGKKPLTTSLDKLLPKSFGKESLRRR\n",
        "\n",
        "Raw pixel RGB values are easy for computers to work with, though they are not very meaningful to the human eye, which is why they are displayed as images on the screen. Similarly, the sequence of amino acids is a compact, convenient representation of the actual molecule, while the more meaningful view of the protein molecule is its 3D structure. For an example, see [Cytidine deaminase](https://www.rcsb.org/structure/1UX1).\n",
        " \n",
        "For you to appreciate and reason about the outputs, you want your models (GANs) to ultimately produce meaningful structures. There are two important common features that make images and proteins both suitable candidates for GANs:\n",
        "\n",
        "* A random combination of building blocks, whether amino acids or pixels, will not produce a realistic outcomes. This means the GAN cannot simply guess! There are meaningful, realistic patterns of pixels and amino acids that it must model and generate.\n",
        "* The mathematical formula for how to evaluate the correctness of the generated item is unknown. For images, correctness is  \"realism\" -- how realistic does a generated image of a dog look? There's no math formula for that, so instead you have another model (the discriminator!) learn to assess that. The same goes for proteins.\n",
        "\n",
        "\n",
        "On the other hand, unlike images, proteins are made out of discrete building blocks (amino acids) which is one of the main causes why GANs tailored for image generation fail to produce high quality protein sequences. A slight change of pixel values (geometric change) does not change how we recognize the image, however, a single modification in the amino acid sequence can make protein inactive. This makes the training of GANs even more challenging. \n",
        "\n",
        "\n",
        "|         | Image      | Protein  |\n",
        "| ------- |:----------:| --------:|\n",
        "| Data type | integers from 0 to 255 | vocab of 20 amino acids |\n",
        "| Dimension| 2D | 1D|\n",
        "| Number of possible variants | $3*256^{size}$ |  $20^{length}$  |\n",
        "\n",
        " \n",
        "For more details please refer to [ProteinGAN published in Nature Machine Intelligence](https://www.nature.com/articles/s42256-021-00310-5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7EFUwbbWy9X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "34c6ec92-cc26-44bf-ad41-859f51d917e7"
      },
      "source": [
        "view = py3Dmol.view(query='pdb:1UX1')\n",
        "view.setStyle({'chain':'A'}, {'cartoon':{'color':'spectrum'}})\n",
        "view.addStyle({'chain':['B','C','D']},{'line':{'hidden':True}})\n",
        "print(\"Cytidine deaminase\")\n",
        "view"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cytidine deaminase\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_16275484276291842\"  style=\"position: relative; width: 640px; height: 480px\">\n        <p id=\"3dmolwarning_16275484276291842\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n      resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n}\n\nvar viewer_16275484276291842 = null;\nvar warn = document.getElementById(\"3dmolwarning_16275484276291842\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_16275484276291842 = $3Dmol.createViewer($(\"#3dmolviewer_16275484276291842\"),{backgroundColor:\"white\"});\n$3Dmol.download(\"pdb:1UX1\", viewer_16275484276291842, {}, function() {\nviewer_16275484276291842.zoomTo();\n\tviewer_16275484276291842.setStyle({\"chain\": \"A\"},{\"cartoon\": {\"color\": \"spectrum\"}});\n\tviewer_16275484276291842.addStyle({\"chain\": [\"B\", \"C\", \"D\"]},{\"line\": {\"hidden\": true}});\nviewer_16275484276291842.render();\n})\n});\n</script>",
            "text/html": [
              "<div id=\"3dmolviewer_16275484276291842\"  style=\"position: relative; width: 640px; height: 480px\">\n",
              "        <p id=\"3dmolwarning_16275484276291842\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n",
              "        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n",
              "        </div>\n",
              "<script>\n",
              "\n",
              "var loadScriptAsync = function(uri){\n",
              "  return new Promise((resolve, reject) => {\n",
              "    var tag = document.createElement('script');\n",
              "    tag.src = uri;\n",
              "    tag.async = true;\n",
              "    tag.onload = () => {\n",
              "      resolve();\n",
              "    };\n",
              "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
              "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
              "});\n",
              "};\n",
              "\n",
              "if(typeof $3Dmolpromise === 'undefined') {\n",
              "$3Dmolpromise = null;\n",
              "  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n",
              "}\n",
              "\n",
              "var viewer_16275484276291842 = null;\n",
              "var warn = document.getElementById(\"3dmolwarning_16275484276291842\");\n",
              "if(warn) {\n",
              "    warn.parentNode.removeChild(warn);\n",
              "}\n",
              "$3Dmolpromise.then(function() {\n",
              "viewer_16275484276291842 = $3Dmol.createViewer($(\"#3dmolviewer_16275484276291842\"),{backgroundColor:\"white\"});\n",
              "$3Dmol.download(\"pdb:1UX1\", viewer_16275484276291842, {}, function() {\n",
              "viewer_16275484276291842.zoomTo();\n",
              "\tviewer_16275484276291842.setStyle({\"chain\": \"A\"},{\"cartoon\": {\"color\": \"spectrum\"}});\n",
              "\tviewer_16275484276291842.addStyle({\"chain\": [\"B\", \"C\", \"D\"]},{\"line\": {\"hidden\": true}});\n",
              "viewer_16275484276291842.render();\n",
              "})\n",
              "});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<py3Dmol.view at 0x7f3df6901d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdi4C_soOMMF"
      },
      "source": [
        "#Toy Example: GAN for Protein Generation\n",
        "\n",
        "We have discussed using GANs for protein synthesis, let‚Äôs try to implement this idea in practise with a simplified example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KglPp1XEynYd"
      },
      "source": [
        "## Setup\n",
        "\n",
        "To begin with, let‚Äôs sort out the setup needed for us to build a toy system. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe8YcPkEds6v",
        "cellView": "form"
      },
      "source": [
        "#@title Installing Dependencies\n",
        "%%capture\n",
        "! apt-get -qq install -y ncbi-blast+\n",
        "! apt-get -qq install -y clustalo\n",
        "! pip install tensorflow-addons --quiet\n",
        "! pip install py3Dmol --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EISZbQl_yE-E",
        "cellView": "form"
      },
      "source": [
        "#@title Fetching Data\n",
        "\n",
        "#/content/cdh_sequences.fasta - training data\n",
        "!gdown --quiet https://drive.google.com/uc?id=1DJun7tjv8stSQVkRMc9z1rq9vZXf7l7t\n",
        "#/content/db_val.phr - blastp database\n",
        "!gdown --quiet https://drive.google.com/uc?id=1LGLiVf5R9zUXFQD8ux5xPiYMRlAIX8za\n",
        "# /content/db_val.psq - blastp database\n",
        "!gdown --quiet https://drive.google.com/uc?id=1pZkIlecl1PFThPrEnCIEDkqWTSHg9ip3\n",
        "#/content/db_val.pin - blastp database\n",
        "!gdown --quiet https://drive.google.com/uc?id=1txigrDFYwz1Zhqeh6_fQ96-CrwUhR2os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU_FiS-wZ8au",
        "cellView": "form"
      },
      "source": [
        "#@title Imports\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1994)\n",
        "from absl import logging\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow_probability.python.distributions import RelaxedOneHotCategorical\n",
        "from IPython.display import display\n",
        "import py3Dmol\n",
        "import shutil\n",
        "\n",
        "logging.set_verbosity(\"ERROR\")\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8EJnLI7bKOf",
        "cellView": "form"
      },
      "source": [
        "#@title Helper Methods\n",
        "\n",
        "\"\"\"Dictionary to map from single letter amino acid to a arbitary id\"\"\"\n",
        "AMINO_ACID_TO_ID = {'0': 0,'A': 1,'C': 2,'D': 3,'E': 4,'F': 5,'G': 6,'H': 7,\n",
        "                    'I': 8,'K': 9,'L': 10,'M': 11,'N': 12,'P': 13,'Q': 14,\n",
        "                    'R': 15,'S': 16,'T': 17,'V': 18,'W': 19,'Y': 20}\n",
        "ID_TO_AMINO_ACID = {v: k for k, v in AMINO_ACID_TO_ID.items()}\n",
        "\n",
        "def fasta_to_dataset(input_file):\n",
        "  \"\"\"\n",
        "  Reads FASTA file into Tensorflow dataset. Note: this does not work with \n",
        "  sequences that are broken into multiple lines. \n",
        "  \"\"\"\n",
        "  df = pd.read_csv(input_file, sep=\"\\n\", lineterminator=\">\", index_col=False, \n",
        "                    names=[\"id\", 'seq']) \n",
        "\n",
        "  def df_iterator():\n",
        "    for v in df.values:\n",
        "      yield [AMINO_ACID_TO_ID[c] for c in v[1].replace(\"\\r\", \"\")]\n",
        "\n",
        "  dataset = tf.data.Dataset.from_generator(df_iterator, tf.int32)\n",
        "  return dataset\n",
        "\n",
        "class GANMonitor(keras.callbacks.Callback):\n",
        "  \"\"\"Training monitor to print generated sequences and run blast\"\"\"\n",
        "  def __init__(self, num_examples=3, latent_dim=128):\n",
        "    self.num_examples = num_examples\n",
        "    self.latent_shape = (num_examples, latent_dim)\n",
        "    self.scores = []\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    latent_vectors = tf.random.normal(shape=self.latent_shape)\n",
        "    gen_seqs = self.model.generator(latent_vectors).numpy().argmax(-1)\n",
        "    fasta = \"\"\n",
        "    print('Generated sequences:')\n",
        "    for i, gen_seq in enumerate(gen_seqs):\n",
        "      seq = \"\".join([ID_TO_AMINO_ACID[a] for a in gen_seq if a != 0])\n",
        "      if len(seq) == 0:\n",
        "        continue\n",
        "      if i < 2:\n",
        "        print(seq)\n",
        "      fasta = fasta + f'>{i}\\n{seq}\\n'\n",
        "\n",
        "    with open('fasta.fasta', 'w') as f:\n",
        "      print(fasta, file=f)\n",
        "    output = !blastp -db /content/db_val -max_target_seqs 1 -outfmt '10 qseqid score evalue pident' -evalue 0.00001 -query fasta.fasta\n",
        "    output = [r.split(',') for r in output]\n",
        "    print('')\n",
        "    if len(output) == 0 or len(output[0]) != 4:\n",
        "      print(f'At the end of epoch {epoch+1} | No significant hits were found')\n",
        "      self.scores.append(0.0)\n",
        "    else:\n",
        "      output_df = pd.DataFrame(output, columns=['qseqid', 'score', 'evalue', \n",
        "                                                'pident'])\n",
        "      output_df = output_df.set_index('qseqid')\n",
        "      avg_score = output_df['score'].astype(float).sum()/self.num_examples\n",
        "      print(f'At the end of epoch {epoch+1} | {len(output_df)}/{self.num_examples} hits were found with average score {avg_score}')\n",
        "      self.scores.append(avg_score)\n",
        "    print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4xWyDTVgKnr"
      },
      "source": [
        "## Reading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q277ab8R9WEU"
      },
      "source": [
        "#### Cytidine Deaminase\n",
        "This demonstration will use a relatively small protein called *cytidine deaminase* for simplicity. Its function in organisms is essential to DNA and RNA degradation. **Our aim is to be able to create variants of this protein that exhibit different properties.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qO-plnDf_Hg"
      },
      "source": [
        "However, in practise we use primary structure which looks like a sequence of capital letters (see below). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh4LQmmRSpJv"
      },
      "source": [
        "\"\"\"Creating dataset from FASTA file\"\"\"\n",
        "dataset = fasta_to_dataset('/content/cdh_sequences.fasta').cache()\n",
        "dataset = dataset.shuffle(12000)\n",
        "dataset = dataset.padded_batch(64, padded_shapes=(160))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWTvd3DkbNZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884b4d9b-41b2-4de6-bc1a-c13284136280"
      },
      "source": [
        "\"\"\"To print a random sequence\"\"\"\n",
        "for batch in dataset:\n",
        "  for seq in batch.numpy()[:8]:\n",
        "    print(\"\".join([ID_TO_AMINO_ACID[a] for a in seq if a != 0]))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLDEPLIHTLMAAARQAREAAYAPYSGDFRVGAAVLTGDGQVFTGCNVENASFGASMCAERVAIFAAVAAGQRQLTALVVIADTPQPIPPCGLCRQVLAEFAPACQVIMANTKGDYQVATMEQLLPYPFEFRQP\n",
            "MNEPLRPGGEATDDGPRIDWDRLREAAVAAREHAYVPYSRFPVGAAALTEDGRVVSGCNVENASYGLTLCAECALVSALHMSGGGRLVAFVCVDGNGDVLMPCGRCRQLLHEHRAPGLRLLTVSGVRTMAEVLPDAFGPENL\n",
            "MDINDLIAQSKVARENAYVPYSKFKVGAALLTEDGKVYHGCNIENSSYGLANCAERTAIFKAVSEGVKRFAAIAIVADTVGPCSPCGACRQVISEFCAPDMPVYLTNLKGDIQHTTVGELLPSAFTPEDLDNAGKHQ\n",
            "MTTAPDWESLRGQARDAMSRAYAPYSRYPVGAAALVDDGRIVTGCNVENASYGLSLCAECGLISALHAGGGGRLTAFTCVDHAGDLLVPCGRCRQLLHEHGGPDLLVDTAAGIRPLSELLPDAFGAGHLKG\n",
            "MSHDLFEAARAAMAKAYAPYSKFPVGAALRTEDGRVFTGANIEVASYPEGWCAETTALGHYIMGGGGKIVEIAVIAERMAKCSPCGGCRQRLAEFCQPETKLYLCDNAGVAETVTMGDMLPYGFRGDILK\n",
            "MKKEKYSFEFERFESKSELAAEQKKVVEEAYDISLNAYAPYSNFNVGASVQLENGEIFSSSNQENASYPVGTCAERGLLAYVNANFPNIKIEKLAVSTPNVNYPLPPCGMCRQYILEIEKKQSQPIEIILSGKEGDVLVINSAKDLLPLHFTDEFLG\n",
            "MDKQFDDLVAMALAARSKAYAPYSKFAVGAAVKCKSGAVFVGANIENRSFGLTICAERVAMGAAVAGGERDFVAIAVTSDSDEPIVPCGACRQFLAEFNPDLIIVGATVRGDRKIDSLSRLLPDPTRGILKHADPS\n",
            "MKKLKIEIDYDFCQFEELSEQDQNLIECAKAAIKNSYAKYSHFHVGAALRLHDGRVVIGANQENAAFPSGLCAERSAIFASQSHYPEQAIDTLAIVAHNEKGFLSDPITPCGACRQVMLEIEDRYKQNVRVLLFGTSGVYILHSVKDLLPFAFVDENMRK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWh6hRfLk7Lg"
      },
      "source": [
        "## Baseline Model \n",
        "\n",
        "Since data is ready, we can move on creating main components of GAN:  discriminator and generator. In this workshop, we will not focus on architectural changes of neural networks (which can be further optimised for protein generation). Hence, discriminator and generator architectures are as plain as possible. The main architectural difference compared to other online tutorials is that here 1D convolution is used instead of 2D."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29vomjsmZ4Wm",
        "outputId": "f5c4dcfb-3779-4f3f-b50a-dbc5d73f6083"
      },
      "source": [
        "#@title Discriminator\n",
        "def get_discriminator_block(filters, kernel_size=3, strides=1):\n",
        "  conv = layers.Conv1D(filters, kernel_size=kernel_size, \n",
        "                       strides=strides, padding=\"valid\")\n",
        "  return conv, layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "def get_discriminator():\n",
        "  return keras.Sequential(\n",
        "      [\n",
        "      keras.layers.InputLayer(input_shape=(160, 21)),\n",
        "      *get_discriminator_block(64),\n",
        "      *get_discriminator_block(128, strides=2),\n",
        "      *get_discriminator_block(128),\n",
        "      *get_discriminator_block(256, strides=2),\n",
        "      *get_discriminator_block(256),   \n",
        "      layers.Flatten(),\n",
        "      layers.Dropout(0.2),\n",
        "      layers.Dense(1)\n",
        "      ], name=\"discriminator\")\n",
        "\n",
        "discriminator = get_discriminator()\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 158, 64)           4096      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 158, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 78, 128)           24704     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 78, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 76, 128)           49280     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 76, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 37, 256)           98560     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 37, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 35, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 35, 256)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8960)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8960)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 8961      \n",
            "=================================================================\n",
            "Total params: 382,465\n",
            "Trainable params: 382,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZI5ql02aATz",
        "outputId": "2ae3a0de-b9ab-41f8-e990-74524be785db"
      },
      "source": [
        "#@title Generator\n",
        "latent_dim = 128\n",
        "\n",
        "def get_generator_block(filters, kernel_size=3, strides=2):\n",
        "  conv_t = layers.Conv1DTranspose(filters, kernel_size=kernel_size, \n",
        "                                  strides=strides, padding=\"same\")\n",
        "  return layers.LeakyReLU(alpha=0.2), conv_t\n",
        "\n",
        "def get_generator():\n",
        "  return keras.Sequential(\n",
        "      [\n",
        "      keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "      layers.Dense(10*128),\n",
        "      layers.Reshape((10, 128)),\n",
        "      *get_generator_block(256),\n",
        "      *get_generator_block(256),\n",
        "      *get_generator_block(128),\n",
        "      *get_generator_block(64),\n",
        "      *get_generator_block(32, strides=1),\n",
        "      layers.LeakyReLU(alpha=0.2),\n",
        "      layers.Conv1D(21, kernel_size=1, padding=\"same\")\n",
        "      ], name=\"generator\")\n",
        "\n",
        "generator = get_generator()\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1280)              165120    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_transpose (Conv1DTran (None, 20, 256)           98560     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 20, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_1 (Conv1DTr (None, 40, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 40, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_2 (Conv1DTr (None, 80, 128)           98432     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 80, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_3 (Conv1DTr (None, 160, 64)           24640     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 160, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_transpose_4 (Conv1DTr (None, 160, 32)           6176      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 160, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 160, 21)           693       \n",
            "=================================================================\n",
            "Total params: 590,485\n",
            "Trainable params: 590,485\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1RnLzVbQSMC"
      },
      "source": [
        "As for baseline, we will create a simplified version of Wasserstein GAN (we will skip the part where the discriminator is trained more times than the generator). For this, we will extend [Model class](https://www.tensorflow.org/api_docs/python/tf/keras/Model) from Keras API and overwrite a few methods.\n",
        " \n",
        "This code is based on the examples from Keras documentation: [dcgan](https://keras.io/examples/generative/dcgan_overriding_train_step/) and [wgan_gp](https://keras.io/examples/generative/wgan_gp)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsaRZS6QaEPx"
      },
      "source": [
        "#@title Baseline Model\n",
        "class GAN(keras.Model):\n",
        "  def __init__(self, discriminator, generator, latent_dim):\n",
        "    super(GAN, self).__init__()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def compile(self, d_loss_fn, g_loss_fn):\n",
        "    \"\"\" Initializes optimizers, metrics, etc \"\"\"\n",
        "    super(GAN, self).compile()\n",
        "    self.d_loss_fn = d_loss_fn\n",
        "    self.g_loss_fn = g_loss_fn\n",
        "    self.d_optimizer = keras.optimizers.Adam(learning_rate=0.003)\n",
        "    self.g_optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "    self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "    self.step = tf.Variable(0.0)\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "  def generate_seqs(self, batch_size):\n",
        "    \"\"\" Using generator produces examples from random vector \"\"\"\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, \n",
        "                                                    self.latent_dim))\n",
        "    generate_seqs = self.generator(random_latent_vectors)    \n",
        "    return generate_seqs\n",
        "\n",
        "  def train_discriminator(self, real_seqs_encoded, generated_seqs):\n",
        "    \"\"\" Train the discriminator \"\"\"\n",
        "    with tf.GradientTape() as tape:             \n",
        "\n",
        "      fake_logits = self.discriminator(generated_seqs, training=True)\n",
        "      real_logits = self.discriminator(real_seqs_encoded, training=True)\n",
        "      d_loss = self.d_loss_fn(d_real=real_logits, d_fake=fake_logits)\n",
        "      \n",
        "    grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "    self.d_optimizer.apply_gradients(zip(grads, \n",
        "                                         self.discriminator.trainable_weights))\n",
        "    return d_loss\n",
        "\n",
        "  def train_generator(self, batch_size):\n",
        "    \"\"\" \n",
        "    Train the generator (note that we should *not* update the weights\n",
        "    of the discriminator)!\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "      generated_seqs = self.generate_seqs(batch_size) \n",
        "      fake_logits = self.discriminator(generated_seqs, training=False)\n",
        "      g_loss = self.g_loss_fn(fake_logits)\n",
        "    grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "    self.g_optimizer.apply_gradients(zip(grads, \n",
        "                                         self.generator.trainable_weights))\n",
        "    return g_loss\n",
        "\n",
        "  def train_step(self, real_seqs):\n",
        "    \"\"\" Performing a single step of the traning \"\"\"\n",
        "    self.step.assign_add(1.0)\n",
        "\n",
        "    # One hot encode input\n",
        "    batch_size = tf.shape(real_seqs)[0]\n",
        "    real_seqs_encoded = tf.one_hot(real_seqs, 21, dtype = tf.float32)\n",
        "    # Generate fake examples\n",
        "    generated_seqs = self.generate_seqs(batch_size)        \n",
        "\n",
        "    # Optimize discriminator\n",
        "    d_loss = self.train_discriminator(real_seqs_encoded, generated_seqs)\n",
        "    # Optimize generator\n",
        "    g_loss = self.train_generator(batch_size)       \n",
        "\n",
        "    # Update metrics\n",
        "    self.d_loss_metric.update_state(d_loss)\n",
        "    self.g_loss_metric.update_state(g_loss)\n",
        "    return {\n",
        "        \"d_loss\": self.d_loss_metric.result(),\n",
        "        \"g_loss\": self.g_loss_metric.result(),\n",
        "    }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgKkod-qjesl"
      },
      "source": [
        "#@title WGAN Loss \n",
        "#source: https://keras.io/examples/generative/wgan_gp/ \n",
        "def discriminator_loss(d_real, d_fake):\n",
        "    real_loss = tf.reduce_mean(d_real)\n",
        "    fake_loss = tf.reduce_mean(d_fake)\n",
        "    return fake_loss - real_loss\n",
        "\n",
        "def generator_loss(d_fake):\n",
        "    return -tf.reduce_mean(d_fake)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz-XPdMc5fU4"
      },
      "source": [
        "Baseline model will be run for 25 epochs (notice that the dataset is repeated 5 times, hence 5*5=25) and we will use BLAST to evaluate generated sequences. While this tool is not perfect, it gives an indication whether sequences are similar to natural ones (for this we will use a validation dataset where sequences are at most 70% similar to the ones used for training). What we are looking for is for BLAST to find some matches with high scores. Just keep in mind, the generator never saw training, not to mention validation sequences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlgzFmLdaIwW"
      },
      "source": [
        "def train(gan, epochs = 5):\n",
        "  callbacks = [GANMonitor(num_examples=10, latent_dim=latent_dim)]\n",
        "  # Dataset is repeated 5 times just to make it easier to see the process\n",
        "  gan.fit(dataset.prefetch(10).repeat(5), epochs=epochs, callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4F0bctGkM7Q",
        "outputId": "810c42ef-cace-42c5-bff4-2f0d3263e9ed"
      },
      "source": [
        "#@title Training the Baseline Model\n",
        "gan = GAN(discriminator=get_discriminator(), \n",
        "          generator=get_generator(), \n",
        "          latent_dim=latent_dim)\n",
        "gan.compile(d_loss_fn=discriminator_loss, g_loss_fn=generator_loss)\n",
        "train(gan)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "845/845 [==============================] - 72s 47ms/step - d_loss: -79020580864.0000 - g_loss: 132101390336.0000\n",
            "Generated sequences:\n",
            "HHHHMHVHVHVHMHVHMHVHMHVHVHVHMHVHVHVHVHVHVHVHMHVHVHHHMHVHMHVHMHVHVHVHMHVHVHVHMHVHVHVHMHVHVHVHMHVHVHVHMHVHVHVHMHVHMHMHMHVHMHMHMHMHVHMHMHVHVHVHMHVHVHHHMHVHMHVHMHVH\n",
            "HPHPSHHHHHVHVHVHVHVHMHVHVHVHMHAHMHMMMHMHMHMHMHMHVHMHMHVHMHMHMHVHVHMHMHVHMHMHMHMHMHMHMHVHMHMHMHVHVHMHMHVHMHVHMHVHMHMHMHVHMHMHMHMHMHMHMHMHMHMHMHMHMHMHMHMHMHMHMHMH\n",
            "\n",
            "At the end of epoch 1 | No significant hits were found\n",
            "\n",
            "Epoch 2/5\n",
            "845/845 [==============================] - 38s 45ms/step - d_loss: 306918272.0000 - g_loss: 244100400.0000\n",
            "Generated sequences:\n",
            "PPSPPPPPPPVPPPPHPPVPNPVHNPVPNPVHPPVPNPVPNPVPNPVHPPVPNPVPNPVPPPVHPPVPNPVPNPVPNPPHPPVPNPVPNPVPNPVHNPVPNPVPNPVHPPVHPPMPNPVHNPVPNPVHNPVPNPVPNPMHPPVHPPMHPPVPNPMHPPVH\n",
            "PPPPPPVPPPMPPPVHPPMHPPAHPPMHMPSHSPMPPPMPPPMHMPMHPPMHMPAHPPMHMPAHSPMMMPAHPPAMMPSPCPMPPPVPNPMHPPMHPPMHPPMHPPVHPHMHPPMHPPVHPPVHNPVHPPMHPPMHPPMHMHMHPPMHMHMHPFMHMHMH\n",
            "\n",
            "At the end of epoch 2 | No significant hits were found\n",
            "\n",
            "Epoch 3/5\n",
            "845/845 [==============================] - 38s 44ms/step - d_loss: 241903808.0000 - g_loss: 19319646.0000\n",
            "Generated sequences:\n",
            "PPSPPPAPPPAPNPPPPPAPNPAPNPAPNPVPNPVPNPAPNPAPNPPPPPAPNPAPPPAPNPPPPPAPNPVPNPAPNPVPPPAPNPAPNPAPNPVPNPAPNPAPNPAPNPPPNPPPNPVPNPVPNPVPNPAPNPAPNPAPNPVPNPVPNPAPNPAPNPVE\n",
            "PPSPPPVPNPVPNPPPNPVPNPVPNPAPNPVPNPVPNPVPNPAPNPVPNPAPNPVPNPAPNPVPNPAPNPVPNPAPNPVPNPAPNPAPNPAPNPVPNPAPNPVPNPAPNPVPNPVPNPVPNPMHNPVHNPMHNPVPNPMHMPMHNPMPNPVPNPAPNPVE\n",
            "\n",
            "At the end of epoch 3 | No significant hits were found\n",
            "\n",
            "Epoch 4/5\n",
            "845/845 [==============================] - 38s 44ms/step - d_loss: 125378072.0000 - g_loss: -5839536.5000\n",
            "Generated sequences:\n",
            "PPPPPPPPPPAPNPPPPPAPNPAPNPAPNPPPNPAPNPVPNPAPNPVPNPAPNPAPNPAPNPVPNPVPNPAPNPAPNPPPNPAPNPAPNPAPNPVPNPAPNPVPNPVPNPVPNPPPNPVPNPAPNPVPNPAPAPVPNPVPNPAPNPVPNPVPNPVPNPVE\n",
            "PPPPPPPPNPAPNPPPNPAPNPAPNPAPNPVPNPAPNPAPNPAPNPAPNPAPAPAPNPAPNPVPNPAPAPAPNPAPNPVPNPAPNPAPNPAPNPVPNPAPNPVPNPVPNPVPNPVPNPVPNPVPNPAPNPPPAPAPNPAPAPVPNPAPAPAPNPAPNPVE\n",
            "\n",
            "At the end of epoch 4 | No significant hits were found\n",
            "\n",
            "Epoch 5/5\n",
            "845/845 [==============================] - 37s 44ms/step - d_loss: 74003704.0000 - g_loss: -12537720.0000\n",
            "Generated sequences:\n",
            "PPPPPPPPPPPPNPPPPPVPNPAPNPVPNPAPPPAPNPPPNPAPNPPPPPAPNPAPNPVPNPPPNPPPNPAPNPVPNPAPPPAPAPAPPPAPNPAPPPAPAPAPPPAPNPPPPPPPNPPPNPPPNPVPNPPPNPVPNPVPNPVPNPEPNPVPNPVPNPAE\n",
            "PPSPPPPPPPPPNPPPNPVPAPAPNPAPNPPPPPAPAPAPNPAPNPVPNPVPNPVPNPAPNPAPNPVPNPPPNPVPNPAPNPVPNPAPNPAPNPAPPPAPAPAPNPAPNPAPNPAPNPVPNPVPNPVPNPVPNPVPNPVPNPVPNPMPNPVPNPVPPPPE\n",
            "\n",
            "At the end of epoch 5 | No significant hits were found\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xy_QkZWQ7fb"
      },
      "source": [
        "This does not look great. Sequences are not looking anything like the ones from the dataset and no hits are found by BLAST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deeX2VzBRXug"
      },
      "source": [
        "## Non-saturating Loss with R1 regularization\n",
        "\n",
        "The first thing that draws attention is that losses are exploding. To mitigate this, we can implement non-saturating loss that will prevent loss from going out of control. This can be achieved by applying softplus operation on discriminator scores (note this has been proposed by Ian Goodfellow in original [Generative Adversarial Networks paper](https://arxiv.org/abs/1406.2661)):\n",
        "\n",
        "$$ f(x) = log(1 + exp(x))$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVmMd7W2SRSS"
      },
      "source": [
        "#@title Non-saturating Loss\n",
        "def discriminator_loss_non_saturating(d_real, d_fake):\n",
        "    d_loss_real = tf.reduce_mean(tf.nn.softplus(-d_real))\n",
        "    d_loss_fake = tf.reduce_mean(tf.nn.softplus(d_fake))\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "    return d_loss\n",
        "\n",
        "def generator_loss_non_saturating(d_fake):\n",
        "    return tf.reduce_mean(tf.nn.softplus(-d_fake))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9equ9uq9STtN",
        "outputId": "0dad2727-8441-47a9-a234-ce301ea5397d"
      },
      "source": [
        "gan = GAN(discriminator=get_discriminator(), \n",
        "          generator=get_generator(), \n",
        "          latent_dim=latent_dim)\n",
        "gan.compile(d_loss_fn=discriminator_loss_non_saturating, \n",
        "            g_loss_fn=generator_loss_non_saturating)\n",
        "train(gan)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "845/845 [==============================] - 39s 44ms/step - d_loss: 131.1320 - g_loss: 1098.5549\n",
            "Generated sequences:\n",
            "PIEIAIEIACECAIETECECECVRECECECEGEGEGEGEGEGEGEAEGEGECECDCECECECECECECECEAQCEIAIECEGEGEGADQAAIAIECEGEGEGADAAPAPIAACECACDRECEIAIEIEIEIAIAIAIAIAIPIARPRPPRQPIRRAIER\n",
            "AIEIAIEIACECAIERACECECVCECECECVGEGEGEGEGEGEGEGECECECECVCECECECVCECECECDRECEIEIVCEGEGEGIDIAPAIAGEGEGEGIGIIPIPIPACECLCDCECECAIEIARECAIQIAIAIAIAPPPQQQAIQAIAIAIPQ\n",
            "\n",
            "At the end of epoch 1 | No significant hits were found\n",
            "\n",
            "Epoch 2/5\n",
            "845/845 [==============================] - 37s 44ms/step - d_loss: 19.8070 - g_loss: 381.3252\n",
            "Generated sequences:\n",
            "VENLETISWPAAEEISIPILETISWPAECEWSRLWECVYGCGEECEYGCGEECEWECGCECEWSCFCAEIISIPCAEEISCPCAEEISCPCAEIIECPCAEELNECECEAELELFEPCWCIISVPVDEFNVW\n",
            "VNNLETISWPAAEEISPPLEIISWPECVWSCLWECVCGCGEECEEGCGEECEWECGCECEWSCFEAETISCPAAEIIECPCAEELTCPAAEAIECCLEIFTCCCEAEEELFEPCWCIIEEEEFEVPWPR\n",
            "\n",
            "At the end of epoch 2 | No significant hits were found\n",
            "\n",
            "Epoch 3/5\n",
            "845/845 [==============================] - 37s 44ms/step - d_loss: 1.7627 - g_loss: 49.0189\n",
            "Generated sequences:\n",
            "VVPVVVLCAAEPNVPPGAPWNVLGGAEPPVPPGAPPSMGAGAGPPAGAAAPPPMGPGAPPPAGAAAPPPMGAAAPLPVFFGAPWNVLGGAEPNVLLGAPPNVLNGAEPVVVNGGMMVVINGAEPNLLFGWPWSVLGGVPVPVLLSWPNSLLLSRNPR\n",
            "VVPVVVLCAAEPNLLFGAPWNVLGGAPPPVPPGAPPSWGAGAGPPAGAAAPPPMGPGAPPPVGAAAPPPMGAAAPLPVFYGAPWNVLNGAEPPILLGWPPPVFGGAEPVVVNGGMMVVLNGVEVNLLLSWPWSVLGGVPVVVLISWPNSLLLSRCNPR\n",
            "\n",
            "At the end of epoch 3 | No significant hits were found\n",
            "\n",
            "Epoch 4/5\n",
            "845/845 [==============================] - 37s 44ms/step - d_loss: 1.1682 - g_loss: 39.1130\n",
            "Generated sequences:\n",
            "IYILSGNITALKAAIIKGLSCIPVGLKVAIIKALTGAHIYELSGGAVPELFAAAVYELSAGIVRALTAAAIYELSANIIALSGAIPPGLKVAIIKGLKGLPCCGCVAEIYGLKSRIIGLPVAEIYGLSGAIVVELKVIIPWGHGGALVVWVLEQT\n",
            "WYILTGNICALKAAIIKGLKGIIGLKAAIIFALTGAAIFELSGGIVPELFAAAVYELSGGIVRELTAAAIRGLSANIIALSGIPPGLAVAIIKALKGAIPCCGCVAIKGLKSRIIALKVAEIKGLSGAIVVELKVIIVWGLSGALVVWVLEPV\n",
            "\n",
            "At the end of epoch 4 | No significant hits were found\n",
            "\n",
            "Epoch 5/5\n",
            "845/845 [==============================] - 37s 44ms/step - d_loss: 0.8338 - g_loss: 31.8483\n",
            "Generated sequences:\n",
            "PPIGLAESSLIKSISLFLSASIRKSAIKGPRKKLPKGACISGPKGIAGSLLACGGAAAVKGPEGSLIACHGAAAVAGPIGGHCACHGECPIKGISSGPGRCRRKCCCCGRSKESACAEPCCIKGESKPCIACAHISCSKSASHPASIGCSGLQSLII\n",
            "PPIGLAESSLIASISLFLGASAHKSAIKGIRKKLPKGPCISGPKGHAGSLLACGLAAAVKGPEGSLIACHGAAAVAGPIGKHGASHGEAIIKGISKGPGCCRRKCCCKGRSKEFAVAEPCCIKGQSKPAIACAHICCIKSASHPASIYPSGLQSLII\n",
            "\n",
            "At the end of epoch 5 | No significant hits were found\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rDLo8iVSxub"
      },
      "source": [
        "While this helps to constrain the loss, there are no observable improvements in terms of quality of generated sequences. Fortunately, based on [Mescheder paper](https://arxiv.org/abs/1801.04406) we know that gradient penalties improve the convergence. R1 - refers to penalties of discriminator gradients on true data distribution:\n",
        " \n",
        "$$R_1(\\psi) = \\frac{\\gamma} 2 \\mathbf{E}_{pD}(x)[||\\nabla D_\\psi(x)||^2]$$\n",
        " \n",
        " \n",
        " \n",
        "In code we can implement this using [GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) and watching input tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lsx1JCMl-F9"
      },
      "source": [
        "#@title R1 Regularization \n",
        "class GANLossR1(GAN):\n",
        "  def train_discriminator(self, real_seqs_encoded, generated_seqs):\n",
        "    # Train the discriminator\n",
        "    with tf.GradientTape() as tape , tf.GradientTape() as r1_penalty_tape:\n",
        "      r1_penalty_tape.watch(real_seqs_encoded)              \n",
        "\n",
        "      fake_logits = self.discriminator(generated_seqs, training=True)\n",
        "      real_logits = self.discriminator(real_seqs_encoded, training=True)\n",
        "      d_loss = self.d_loss_fn(d_real=real_logits, d_fake=fake_logits)\n",
        "\n",
        "      real_grads = r1_penalty_tape.gradient(tf.reduce_sum(real_logits), \n",
        "                                            [real_seqs_encoded])[0]\n",
        "      r1 = tf.reduce_sum(tf.square(real_grads), axis=[1, 2])\n",
        "\n",
        "      d_loss +=  r1 * 5.0 # a hyperparameter which can be tuned \n",
        "\n",
        "    grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "    self.d_optimizer.apply_gradients(zip(grads, \n",
        "                                         self.discriminator.trainable_weights))\n",
        "    return d_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppd9ojcrl1JW",
        "outputId": "aad8f76f-3beb-42bc-fc30-675ab7032a24"
      },
      "source": [
        "gan = GANLossR1(discriminator=get_discriminator(), \n",
        "                generator=get_generator(), \n",
        "                latent_dim=latent_dim)\n",
        "gan.compile(d_loss_fn=discriminator_loss_non_saturating, \n",
        "            g_loss_fn=generator_loss_non_saturating)\n",
        "train(gan)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "845/845 [==============================] - 50s 56ms/step - d_loss: 1.0985 - g_loss: 1.3651\n",
            "Generated sequences:\n",
            "AGAIGAYAGLIGTAAFRLPCREELLKGVSSKAEEGTENALVIGAEIALVIGAEVAGAIGASVAGVIGAVAGAIGTAAALSELRGLAYEGLRGILDEGNAEVAGVIGAEVAGVIPVPIAPAYAKAALDAGARGGA\n",
            "AAGAVGIPGAGAAGAAGAGAAEGTLDEGAEGTRDAGVLSGVAGTVLEPRSPLRGNALAGNAERALVIGAVAGAIGVAAALARYSPNAGAVLSKSAGAAGATGAGAVLTKGAGAVLTTEAGGVLSKKAGAVLRPQAGAVLRY\n",
            "\n",
            "At the end of epoch 1 | No significant hits were found\n",
            "\n",
            "Epoch 2/5\n",
            "845/845 [==============================] - 47s 56ms/step - d_loss: 1.1754 - g_loss: 1.0620\n",
            "Generated sequences:\n",
            "MKYPENEACVGANAASADGKGRRVKGVPYSKYIPSAFYVPNFAPVQVILSEANAKAAAISVNVEMKYIDNVGIVGNRNSVTNVAIDGNAAAVPDVNKAVDVLITVVGIRNRVVTVPPTGYAANAIAEAADFTGGDSGGVVGGG\n",
            "MKETGKEDGGVIVKDGALTKRNVAGLGKVVVSVDGNENRATVAAFAIKPTVTGADDCGVIVAEKALFTLKEGAIFIVVVGGVVVGGSNIVNVVTNPPAEAAAFSVKVNVIVVVKIPVIVLVAIKVDVKGKAAGEGKTKAANA\n",
            "\n",
            "At the end of epoch 2 | No significant hits were found\n",
            "\n",
            "Epoch 3/5\n",
            "845/845 [==============================] - 47s 56ms/step - d_loss: 1.0964 - g_loss: 1.1102\n",
            "Generated sequences:\n",
            "MTETLLPSVLKPQSEFAASPESSTTAGARAGAFAARPCGAIVIANSGAALKNCAEAVAALVAEVVVADKGKRAAAGAALVKVAPPCGTTRGARLLALRPYGCLLPHPVGCIGDIVLLATVVLTLSECGLKDCGERAA\n",
            "VALLVADFVAAPVSKFVVLAVAALVAVLVAERVAALVAELLEAIAVTIDGCLGTLAEKEVGHASRIVGAAERATAVGLFSRIVLPCGACRALAAGVMSDGDLILLESIAETIDGIAELPEFLGPVSAFVSDF\n",
            "\n",
            "At the end of epoch 3 | 1/10 hits were found with average score 8.7\n",
            "\n",
            "Epoch 4/5\n",
            "845/845 [==============================] - 47s 56ms/step - d_loss: 1.1161 - g_loss: 1.0441\n",
            "Generated sequences:\n",
            "MNLEVAAESAVGRALVMGADAGFCAARSERVRARKIIENGCNVENASYVGLVAGAGAALSERENAELVAYAGAIVGNASEFELVAIAGAPNSENVEFDGEEILTKKAGRGASVGSRSFCVEVFPFGNIEVIA\n",
            "MSDQVLQPLSDFTALLDALVAYAGAAVGRAEAALGVVYSGCNVENASYGDMEEILTKKAVGIFSTGSRSFCAIRVGAGAKPYVPPCPPCRQVRQPVVLTDEGEVYVFPFGPISVCNTPERTTSLPCDAFELVEISPLPGGRALLDTRLLLLKELVAFSAF\n",
            "\n",
            "At the end of epoch 4 | 5/10 hits were found with average score 56.9\n",
            "\n",
            "Epoch 5/5\n",
            "845/845 [==============================] - 47s 56ms/step - d_loss: 1069.3180 - g_loss: 19.3068\n",
            "Generated sequences:\n",
            "HHTHHGAVASHSTGSSSGSTSGSSHVGSVSHLHSCSCRHAHAHALLHAHHHQHAHAHAHALLHQHHHQHHHAHGHHHCGAHDQALDHAHHHAHHHAHAAAHHHHVSTHSTHSTASAHTTASAHSTASSHN\n",
            "MHHHHQHHHQHHHHHHHAHAHAHSHSMSMLHSLSGLLLHHHLHCHAHHHAHHHAHAAALSLAHSGSASVLHVTHAHRTAASHTPSSRAAQALSLAAIQSGSHLHGHTALLHTHHNTATHASLMSMSHSSSMR\n",
            "\n",
            "At the end of epoch 5 | No significant hits were found\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anzVrwQaV8Ps"
      },
      "source": [
        "## Categorical Reparameterization Trick \n",
        "\n",
        "This time it looks better and we even (not always) get some hits from BLAST. Although we ignore the fact that our input is one-hot encoded. If we produce sequences using the generator and then perform argmax operation (which is not differentiable, unfortunately), we see that the discriminator scores (the higher, the better) differ. That indicates that the discriminator leverages the fact that generated sequences are not completely one-hot encoded. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_9CyE_-6Bcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8305ed8-d1e4-4663-ab37-9cf3a121ae7c"
      },
      "source": [
        "gen_seqs = gan.generate_seqs(16)\n",
        "gen_seqs[:2, 45].numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.47555086,  0.04263934,  0.2675383 , -0.12096094, -0.2100828 ,\n",
              "         0.03005927, -0.02424216, -0.267574  ,  0.05772799, -0.00337951,\n",
              "         0.3713896 , -0.04744346, -0.1166904 ,  0.02174968, -0.41567218,\n",
              "         0.5371393 ,  0.56006175,  0.15161656, -0.07408412, -0.04621504,\n",
              "         0.06380918],\n",
              "       [ 0.59507877, -0.17969336,  0.01274711, -0.02815276,  0.07634322,\n",
              "        -0.02219142, -0.08892188,  0.2606557 , -0.1362936 , -0.03028421,\n",
              "         0.29796565, -0.20806435, -0.14027461, -0.02924195, -0.14338237,\n",
              "        -0.01997772,  0.0839853 ,  0.10726281,  0.2792397 , -0.02175916,\n",
              "        -0.00970733]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtNjoWWT8CPx",
        "outputId": "82060df1-b6f5-46d7-fde2-eb13e78588ba"
      },
      "source": [
        "gan.discriminator(gen_seqs).numpy().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-24.385616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWm0hNc_8HVC",
        "outputId": "c4c0f73f-735a-434d-d9b7-43c20ef8cff2"
      },
      "source": [
        "one_hot_encoded_gen = tf.one_hot(tf.math.argmax(gen_seqs, axis=-1), 21)\n",
        "gan.discriminator(one_hot_encoded_gen).numpy().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-10.1049"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpGf-DzrWg5u"
      },
      "source": [
        "Ideally, we want the generator to produce one-hot encoded sequences straight away so that the discriminator could not use this to distinguish generated from real. To achieve this, we will use [RelaxedOneHotCategorical](https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/RelaxedOneHotCategorical) to approximate 21-class one-hot categorical distribution while allowing us optimise the model end-to-end.\n",
        "\n",
        "To read more about this: [Gumbel-Softmax (Jang et al., 2016)](https://arxiv.org/abs/1611.01144) and [Concrete (Maddison et al., 2016)](https://arxiv.org/abs/1611.00712)\n",
        "\n",
        "An example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDMgxJopXvML",
        "outputId": "8adf65a8-3b8d-4eac-a413-27bfeaca21c4"
      },
      "source": [
        "logits = [0.85, 0.1, 0.05]\n",
        "RelaxedOneHotCategorical(temperature=0.0001, logits=logits).sample().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W6j44VmYAeD"
      },
      "source": [
        "The implementation is quite simple. The only hyperparameter is temperature which should decrease as training progresses. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkXi33Mali4L"
      },
      "source": [
        "#@title Implementation of One Hot approximation\n",
        "class GANLossR1Relaxed(GANLossR1):\n",
        "  \"\"\" Using generator produces examples from random vector \"\"\"\n",
        "  def generate_seqs(self, batch_size):\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, \n",
        "                                                    self.latent_dim))\n",
        "    generate_seqs = self.generator(random_latent_vectors)    \n",
        "    temperature = 1 / tf.math.log(self.step)\n",
        "    generate_seqs = RelaxedOneHotCategorical(temperature=temperature,\n",
        "                                            logits=generate_seqs).sample()\n",
        "    return generate_seqs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBIFZCy-lh-S",
        "outputId": "b51a960d-1f35-4862-90cc-4305f8520767"
      },
      "source": [
        "#@title Training Final Version \n",
        "gan = GANLossR1Relaxed(discriminator=get_discriminator(), \n",
        "                       generator=get_generator(), \n",
        "                       latent_dim=latent_dim)\n",
        "gan.compile(d_loss_fn=discriminator_loss_non_saturating, \n",
        "            g_loss_fn=generator_loss_non_saturating)\n",
        "train(gan)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "845/845 [==============================] - 51s 56ms/step - d_loss: 1.2360 - g_loss: 0.9207\n",
            "Generated sequences:\n",
            "MKKEEEEEEEEARREEEAERRRKRAAAAAVAAAGGGAGGAAAAAAAAAAGGGGGGAAAGAAAGAAAEEEEEEEAAAAAAACGGGGGGGCCCCCCGCPEEEEEEEEPEPPPPEEEEEEEEEEPEPPPEEEPG\n",
            "MTEEEEEEEEEAPEEEEEGAAAEAMEEEGVGGCCGCCCCGGAAAAAAAAAAANGGFNVGAAAAAAAAAAAVEAVGAAAVGEGGGGGGGGGPPPPGGGPEEPPEPPPPPGGGGCGGAAAAAAAAEGVGAAAAAAAEEAAGAAAAAMKK\n",
            "\n",
            "At the end of epoch 1 | 1/10 hits were found with average score 9.0\n",
            "\n",
            "Epoch 2/5\n",
            "845/845 [==============================] - 48s 57ms/step - d_loss: 1.2658 - g_loss: 0.8422\n",
            "Generated sequences:\n",
            "MTDDELIEEAAEAAAAEAAKAKVALAYAGRAESAFRVGRVVTNENASYGLTNCAERTAIIAAIAMSDREFQELAYASDTEAYAPYPIPPCGACRQVALLDDGIVVTGLAFGFPELTVKELLPYAFTKK\n",
            "MTKAARAAARAAARAAAAYYYRFYSKFHVGAAATYSANNAASNNNNNAAYYNANNAARAAARAAAAYASRPYSHFIVGAAAAAAALAAAEAAAAIAASDDPDLPVINSDGRQKELTEIFAEGDNAKEELAYAFG\n",
            "\n",
            "At the end of epoch 2 | 10/10 hits were found with average score 189.7\n",
            "\n",
            "Epoch 3/5\n",
            "845/845 [==============================] - 48s 57ms/step - d_loss: 1.3093 - g_loss: 0.7923\n",
            "Generated sequences:\n",
            "MTLIEELLEEAIIMLLEEALENAALIAAIRAARAYSAAPPYSNFKVCASYLLTECAAEAAVFSDGCAIFAAIGAGQPLVIFEFDDPVIPELLCPCGRVIQELLAHDFPPPDIQETTVDELLPGAFYTEDLK\n",
            "MTEEELIEAAIKAREIAAVPYSNFPVGAARDAAVVVAYGKVFVGNCAEGLSYGKTIVAGGTAIAEGGRVFAEAVAVGTRESAGQPPTPCCGCRQVIFENADEGTAIVGLNAENASYGAGRTLLPKAFSGELLPISPCGFC\n",
            "\n",
            "At the end of epoch 3 | 10/10 hits were found with average score 173.1\n",
            "\n",
            "Epoch 4/5\n",
            "845/845 [==============================] - 48s 57ms/step - d_loss: 1.3285 - g_loss: 0.7710\n",
            "Generated sequences:\n",
            "MSELEEAGAIAMRAAAYAPYSHFPVGAALAADDGQVGANAENSYFPVGAVVAEGGRVLTGCNVENASYPLTIVAIAAGGDGDPPTPCGGCRQQLAEALLGPDVILTNPYGDIQEITVAELLPYAFSAEAMEQAYAEYSWAAFSKA\n",
            "MSYDELIEEAREARERAYVPYSRFQVGAALLTEDGQVFTGCNIENASYGPTNCAERTAIFSAVSEGEREFSAIAVAGRGDGDDPIAPCGACRQVLAEFSGDDDVIIVIGETKEFVSPCAERRQTLAELLPFSFA\n",
            "\n",
            "At the end of epoch 4 | 10/10 hits were found with average score 200.7\n",
            "\n",
            "Epoch 5/5\n",
            "845/845 [==============================] - 48s 57ms/step - d_loss: 1.3320 - g_loss: 0.7683\n",
            "Generated sequences:\n",
            "MLKEFLIDALKEAHARAYAPYSHFKVGAAALTADGKVYKGCNIENASYGLCNCAERTAFFKAVSEGERAFKELAYAGGGNGEPVTPPMDAAVVAGQQSHSKFAPIAVTGRSDDNAVIIVDKLPHSFTPQANAENA\n",
            "MDTQQLIKLAIEARKYPYSKFSVGAALAAAKTPDGTIFEGCNIENASYPLTNCAERTAIFKAVSEGERDFKALAIVADTDGPISPCGACRQVMSEFCKPDMKVYLTNLNGQELVILTTLVAYLTPHSDDDGEVK\n",
            "\n",
            "At the end of epoch 5 | 10/10 hits were found with average score 203.2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXVnLsmKwgXO"
      },
      "source": [
        "Nice! This time, we got some matches with high identity. This is a good indication that the GAN works well in generating realistic protein sequences. Even generated sequences now look much more like being one hot encoded (the discriminator scores are much closer). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qP1aKd7YW75",
        "outputId": "aa669b94-4488-41aa-901c-3adf947cf10a"
      },
      "source": [
        "gen_seqs2 = gan.generate_seqs(2)\n",
        "gen_seqs2[:, 45].numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm_REVJBPIY6",
        "outputId": "11fd117d-747d-4429-8219-6610d508c69d"
      },
      "source": [
        "gan.discriminator(gen_seqs2).numpy().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.41770518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfLtOlQ_PL5v",
        "outputId": "d1ef7c53-944d-447b-bf28-98a82ba18615"
      },
      "source": [
        "one_hot_encoded_gen = tf.one_hot(tf.math.argmax(gen_seqs2, axis=-1), 21)\n",
        "gan.discriminator(one_hot_encoded_gen).numpy().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.41672885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gEvaVhywyGC"
      },
      "source": [
        "## Structure of Generated Sequence\n",
        "\n",
        "With the incredible breakthrough of [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2), now we have an ability to accurately predict structures from amino acid sequences. I took one of generated sequences by our simplified GAN:\n",
        "> MTLDELIDAAIEARERAYVPYSGFKVGAALLTKDGTIYTGCNVENAAYPYGLCACAEVSAMCSASGHSEIKVLVVVGDTERPGSPCGACRQVMAEFYELGEALIIAITWNPIDLTTVSELLPHSFNGELLPK\n",
        "\n",
        "And then used AlphaFold2 to predict the structure. The image below shows aligned structures of generated sequence (green) and cyan (determined experimentally: PDB ID: [1ux1](https://www.rcsb.org/structure/1UX1)). Bear in mind that sequences are not identical. In fact they are only 46.4% similar (have identical amino acids). \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1_3c0sOC27oDiL9dsU0lTmZgSTSNPke42\" />\n",
        "\n",
        "That is incredible: being able to come up with a unique sequence of amino acids that folding in the same structure is a small, but significant step towards understanding the *protein language*. Furthermore, this allows us to search for interesting proteins with unique or improved properties (for example,stability or expresability) without impairing the function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm5zc1AlkMe4"
      },
      "source": [
        "## Concluding Remarks\n",
        "\n",
        "In summary, this has been a demonstration of how GANs can be extended/modified to work well when inputs are discrete. I hope this workshop serves as a good starting point for everyone who wants to use GANs to produce high quality examples which are not necessarily images. \n"
      ]
    }
  ]
}